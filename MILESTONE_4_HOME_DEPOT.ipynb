{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TO PERFORM SEMANTIC SEGMENTATION ON THE HOME DEPOT DATASET**\n",
        "\n"
      ],
      "metadata": {
        "id": "uvhK3TVGRY9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import datetime\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "from mrcnn.visualize import display_instances\n",
        "\n",
        "#The root directory part\n",
        "root = r\"C:\\Users\\devik\\Downloads\\HomeDepot\\HomeDepotDataset\"\n",
        "sys.path.append(root) \n",
        "#The weights file for Mask RCNN which is downloaded\n",
        "maskrcnn_weights = os.path.join(root, \"mask_rcnn_coco.h5\")\n",
        "dir_logs = os.path.join(root, \"logs\")\n",
        "\n",
        "\n",
        "# Training of the custom dataset of Home Depot\n",
        "class CustomConfig(Config):\n",
        "    name = \"object\"\n",
        "    no_images = 2\n",
        "    # 1 is added in the number of classes as it considers the bakground. \n",
        "    num_classes = 1 + 10 \n",
        "    no_of_epochs = 10\n",
        "    confidence = 0.85\n",
        "\n",
        "#Considering the Home Depot dataset to perform Semantic Segmnetation\n",
        "class CustomDataset(utils.Dataset):\n",
        "\n",
        "    def load_custom(self, dataset_dir, subset):\n",
        "        # The 10 categories of Kitchen from the Home Depot website are added to the class.\n",
        "        self.add_class(\"object\", 1, \"Sinks\")\n",
        "        self.add_class(\"object\", 2, \"Cabinets\")\n",
        "        self.add_class(\"object\", 3, \"Countertops\")\n",
        "        self.add_class(\"object\", 4, \"Dinnerware\")\n",
        "        self.add_class(\"object\", 5, \"Skillets\")\n",
        "        self.add_class(\"object\", 6, \"Cutting Boards\")\n",
        "        self.add_class(\"object\", 7, \"Mixing Bowls\")\n",
        "        self.add_class(\"object\", 8, \"Toaster Ovens\")\n",
        "        self.add_class(\"object\", 9, \"Wall Ovens\")\n",
        "        self.add_class(\"object\", 10, \"Garbage Disposals\")\n",
        "\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        # Path for the annotations of the dataset which is stored in the json format\n",
        "        ann = json.load(open(r'C:\\Users\\devik\\Downloads\\HomeDepot\\HomeDepotDataset\\train\\annotations.json'))\n",
        "        data_annotations = list(ann.values()) \n",
        "\n",
        "        data_annotations = [a for a in data_annotations if a['regions']]\n",
        "        for a in annotations:\n",
        "    \n",
        "            # Creating a polygon that creates an outline for an instance\n",
        "            polygons = [r['shape_attributes'] for r in a['regions']] \n",
        "            obj = [s['region_attributes']['name'] for s in a['regions']]\n",
        "            print(\"objects:\",obj)\n",
        "            dict = {\"Sinks\": 1,\"Cabinets\": 2,\"Countertops\": 3,\"Dinnerware\": 4,\"Skillets\": 5,\"Cutting Boards\": 6,\"Mixing Bowls\": 7,\"Toaster Ovens\": 8,\"Wall Ovens\": 9,\"Garbage Disposals\": 10} #,\"xyz\": 3}\n",
        "            num_ids = [dict[a] for a in obj]\n",
        "            print(\"numids\",num_ids)\n",
        "            img_path = os.path.join(dataset_dir, a['filename'])\n",
        "            img = skimage.io.imread(img_path)\n",
        "            height, width = img.shape[:2]\n",
        "\n",
        "            self.add_image(\"object\",  \n",
        "                img_id=a['filename'],  # An unique image id must be used as a filename.\n",
        "                path=img_path, width=width, height=height, polygons=polygons, num_ids=num_ids)\n",
        "\n",
        "     \"\"\"\n",
        "    def custom_visualize(test_image, model, colors, classes, draw_bbox, mrcnn_visualize, instance_segmentation):\n",
        "    detections = model.detect([test_image], verbose=1)[0]\n",
        "\n",
        "    if mrcnn_visualize:\n",
        "        matplotlib.use('TkAgg')\n",
        "        visualize.display_instances(test_image, detections['rois'], detections['masks'], detections['class_ids'], classes, detections['scores'])\n",
        "        return\n",
        "\n",
        "    if instance_segmentation:\n",
        "        hsv = [(i / len(detections['rois']), 1, 1.0) for i in range(len(detections['rois']))]\n",
        "        colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "        random.seed(42)\n",
        "        random.shuffle(colors)\n",
        "\n",
        "    for i in range(0, detections[\"rois\"].shape[0]):\n",
        "        classID = detections[\"class_ids\"][i]\n",
        "\n",
        "        mask = detections[\"masks\"][:, :, i]\n",
        "        if instance_segmentation:\n",
        "            color = colors[i][::-1]\n",
        "        else:\n",
        "            color = colors[classID][::-1]\n",
        "\n",
        "        # To visualize the pixel-wise mask of the object\n",
        "        test_image = visualize.apply_mask(test_image, mask, color, alpha=0.5)\n",
        "\n",
        "    test_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if draw_bbox:\n",
        "        for i in range(0, len(detections[\"scores\"])):\n",
        "            (startY, startX, endY, endX) = detections[\"rois\"][i]\n",
        "\n",
        "            classID = detections[\"class_ids\"][i]\n",
        "            label = classes[classID]\n",
        "            score = detections[\"scores\"][i]\n",
        "\n",
        "            if instance_segmentation:\n",
        "                color = [int(c) for c in np.array(colors[i]) * 255]\n",
        "\n",
        "            else:\n",
        "                color = [int(c) for c in np.array(colors[classID]) * 255]\n",
        "\n",
        "            cv2.rectangle(test_image, (startX, startY), (endX, endY), color, 2)\n",
        "            text = \"{}: {:.2f}\".format(label, score)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.putText(test_image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    return test_image\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # The generate_mask() method needs the size of the images to convert polygons to masks.\n",
        "    def generate_mask(self, img_id):\n",
        "    \n",
        "        #The masks generated are a bool array of shape which consists of height, width and instance count with\n",
        "        #one mask per instance.\n",
        "        \n",
        "        img_data = self.img_data[img_id]\n",
        "        if img_data[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).generate_mask(img_id)\n",
        "\n",
        "        # Converting the polygons to a bitmap mask of shape.\n",
        "        data = self.img_data[img_id]\n",
        "        if data[\"source\"] != \"object\":\n",
        "            return super(self.__class__, self).generate_mask(img_id)\n",
        "        num_ids = data['num_ids']\n",
        "        mask = np.zeros([data[\"height\"], data[\"width\"], len(data[\"polygons\"])],dtype=np.uint8)\n",
        "        for i, p in enumerate(data[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "        \txx, yy = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "\n",
        "        \tmask[xx, yy, i] = 1\n",
        "\n",
        "        num_ids = np.array(num_ids, dtype=np.int32)\n",
        "        return mask, num_ids \n",
        "\n",
        "    def img_refer(self, img_id):\n",
        "        data = self.img_data[img_id]\n",
        "        if data[\"source\"] == \"object\":\n",
        "            return data[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).img_refer(img_id)\n",
        "\n",
        "def train_dataset(model):\n",
        "    \n",
        "    # Home Depot model: Training dataset\n",
        "    train_data = CustomDataset()\n",
        "    train_data.load_custom(r\"C:\\Users\\devik\\Downloads\\HomeDepot\\HomeDepotDataset\", \"train\")\n",
        "    train_data.prepare()\n",
        "\n",
        "    # Home Depot Model: Validation dataset\n",
        "    val_data = CustomDataset()\n",
        "    val_data.load_custom(r\"C:\\Users\\devik\\Downloads\\HomeDepot\\HomeDepotDataset\", \"val\")\n",
        "    val_data.prepare()\n",
        "\n",
        "    print(\"The working heads of the training model\")\n",
        "    model.train_dataset(train_data, val_data,learning_rate=config.LEARNING_RATE,epochs=10,layers='heads')\n",
        "\t\t\t\t\n",
        "\t\t\t\t\t\t\t\n",
        "config = CustomConfig()\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,model_dir=dir_logs)\n",
        "weights = maskrcnn_weights\n",
        "\n",
        "if not os.path.exists(weights):\n",
        "  utils.download_trained_weights(weights)\n",
        "\n",
        "model.load_weights(weights, by_name=True, exclude=[ \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "#Finally training the model\n",
        "train(model)\t"
      ],
      "metadata": {
        "id": "WodiunHcRz_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}